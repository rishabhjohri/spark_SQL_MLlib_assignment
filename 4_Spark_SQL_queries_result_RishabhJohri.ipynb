{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b978228a",
   "metadata": {},
   "source": [
    "# Part 3: Spark SQL & DataFrames (Google Colab Notebook)\n",
    "This notebook implements Part 3 of the graded assessment: \n",
    "- Load CSVs (customers, orders, products)\n",
    "- Run Spark SQL queries (total spend > X, monthly trends, top-selling category)\n",
    "- Save results as Parquet and JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RetailAnalytics-Part3\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9347cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_path = \"/mnt/data/customers.csv\"\n",
    "orders_path    = \"/mnt/data/orders.csv\"\n",
    "products_path  = \"/mnt/data/products.csv\"\n",
    "\n",
    "customers_df = spark.read.csv(customers_path, header=True, inferSchema=True)\n",
    "orders_df    = spark.read.csv(orders_path,    header=True, inferSchema=True)\n",
    "products_df  = spark.read.csv(products_path,  header=True, inferSchema=True)\n",
    "\n",
    "print(\"Customers columns:\", customers_df.columns)\n",
    "print(\"Orders columns:\", orders_df.columns)\n",
    "print(\"Products columns:\", products_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5804badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_present(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "ord_qty_col = first_present(orders_df, [\"quantity\", \"qty\", \"Quantity\"])\n",
    "ord_unit_price_col = first_present(orders_df, [\"unit_price\", \"UnitPrice\", \"unitprice\", \"price_per_unit\"])\n",
    "ord_total_amt_col = first_present(orders_df, [\"total_amount\", \"TotalAmount\", \"amount\", \"Amount\", \"order_amount\"])\n",
    "ord_price_col = first_present(orders_df, [\"price\", \"Price\", \"unit_price\", \"UnitPrice\"])\n",
    "ord_date_col = first_present(orders_df, [\"order_date\", \"OrderDate\", \"date\", \"Date\", \"order_datetime\", \"timestamp\"])\n",
    "\n",
    "if ord_date_col is None:\n",
    "    raise ValueError(\"Could not find an order date column in orders file.\")\n",
    "\n",
    "orders_with_date = orders_df.withColumn(\n",
    "    \"_order_ts\",\n",
    "    F.to_timestamp(F.col(ord_date_col))\n",
    ").withColumn(\n",
    "    \"order_date\",\n",
    "    F.to_date(F.col(\"_order_ts\"))\n",
    ").drop(\"_order_ts\")\n",
    "\n",
    "if ord_qty_col and ord_unit_price_col:\n",
    "    orders_clean = orders_with_date.withColumn(\n",
    "        \"revenue\",\n",
    "        F.col(ord_qty_col).cast(\"double\") * F.col(ord_unit_price_col).cast(\"double\")\n",
    "    )\n",
    "elif ord_total_amt_col:\n",
    "    orders_clean = orders_with_date.withColumn(\n",
    "        \"revenue\",\n",
    "        F.col(ord_total_amt_col).cast(\"double\")\n",
    "    )\n",
    "elif ord_qty_col and ord_price_col:\n",
    "    orders_clean = orders_with_date.withColumn(\n",
    "        \"revenue\",\n",
    "        F.col(ord_qty_col).cast(\"double\") * F.col(ord_price_col).cast(\"double\")\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"Could not derive revenue.\")\n",
    "\n",
    "orders_clean.select(\"order_date\",\"revenue\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce18efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.createOrReplaceTempView(\"customers\")\n",
    "orders_clean.createOrReplaceTempView(\"orders\")\n",
    "products_df.createOrReplaceTempView(\"products\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3816b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_key = None\n",
    "for c in [\"customer_id\", \"cust_id\", \"CustomerID\", \"Customer_Id\"]:\n",
    "    if c in customers_df.columns:\n",
    "        cust_key = c\n",
    "        break\n",
    "\n",
    "ord_cust_key = None\n",
    "for c in [\"customer_id\", \"cust_id\", \"CustomerID\", \"Customer_Id\"]:\n",
    "    if c in orders_clean.columns:\n",
    "        ord_cust_key = c\n",
    "        break\n",
    "\n",
    "customers_std = customers_df.withColumnRenamed(cust_key, \"customer_id_std\")\n",
    "orders_std = orders_clean.withColumnRenamed(ord_cust_key, \"customer_id_std\")\n",
    "customers_std.createOrReplaceTempView(\"customers_std\")\n",
    "orders_std.createOrReplaceTempView(\"orders_std\")\n",
    "\n",
    "X = 500.0\n",
    "\n",
    "sql_customers_over_X = f\"\"\"\n",
    "SELECT\n",
    "  c.*,\n",
    "  ROUND(SUM(o.revenue), 2) AS total_spend\n",
    "FROM customers_std c\n",
    "JOIN orders_std o\n",
    "  ON c.customer_id_std = o.customer_id_std\n",
    "GROUP BY c.*\n",
    "HAVING SUM(o.revenue) > {X}\n",
    "ORDER BY total_spend DESC\n",
    "\"\"\"\n",
    "\n",
    "customers_over_X_df = spark.sql(sql_customers_over_X)\n",
    "customers_over_X_df.show(20, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995c08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_monthly_trend = \"\"\"\n",
    "SELECT\n",
    "  DATE_FORMAT(order_date, 'yyyy-MM') AS year_month,\n",
    "  ROUND(SUM(revenue), 2) AS monthly_revenue,\n",
    "  COUNT(*) AS order_count\n",
    "FROM orders_std\n",
    "GROUP BY DATE_FORMAT(order_date, 'yyyy-MM')\n",
    "ORDER BY year_month\n",
    "\"\"\"\n",
    "\n",
    "monthly_trend_df = spark.sql(sql_monthly_trend)\n",
    "monthly_trend_df.show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18afecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_key_orders = None\n",
    "for c in [\"product_id\", \"prod_id\", \"ProductID\", \"Product_Id\"]:\n",
    "    if c in orders_std.columns:\n",
    "        prod_key_orders = c\n",
    "        break\n",
    "\n",
    "prod_key_products = None\n",
    "for c in [\"product_id\", \"prod_id\", \"ProductID\", \"Product_Id\"]:\n",
    "    if c in products_df.columns:\n",
    "        prod_key_products = c\n",
    "        break\n",
    "\n",
    "cat_col = None\n",
    "for c in [\"category\", \"Category\", \"category_name\", \"CategoryName\"]:\n",
    "    if c in products_df.columns:\n",
    "        cat_col = c\n",
    "        break\n",
    "\n",
    "products_std = products_df.withColumnRenamed(prod_key_products, \"product_id_std\") \\                          .withColumnRenamed(cat_col, \"category_std\")\n",
    "orders_w_prod = orders_std.withColumnRenamed(prod_key_orders, \"product_id_std\")\n",
    "\n",
    "products_std.createOrReplaceTempView(\"products_std\")\n",
    "orders_w_prod.createOrReplaceTempView(\"orders_w_prod\")\n",
    "\n",
    "sql_top_category = \"\"\"\n",
    "SELECT\n",
    "  p.category_std AS category,\n",
    "  ROUND(SUM(o.revenue), 2) AS total_revenue,\n",
    "  SUM(1) AS order_rows\n",
    "FROM orders_w_prod o\n",
    "JOIN products_std p\n",
    "  ON o.product_id_std = p.product_id_std\n",
    "GROUP BY p.category_std\n",
    "ORDER BY total_revenue DESC\n",
    "\"\"\"\n",
    "\n",
    "top_category_df = spark.sql(sql_top_category)\n",
    "top_category_df.show(20, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0c145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_base = \"/content/output/retail_analytics\"\n",
    "\n",
    "(\n",
    "    customers_over_X_df\n",
    "    .coalesce(1)\n",
    "    .write.mode(\"overwrite\")\n",
    "    .parquet(f\"{output_base}/customers_over_X_parquet\")\n",
    ")\n",
    "(\n",
    "    customers_over_X_df\n",
    "    .coalesce(1)\n",
    "    .write.mode(\"overwrite\")\n",
    "    .json(f\"{output_base}/customers_over_X_json\")\n",
    ")\n",
    "\n",
    "(\n",
    "    monthly_trend_df\n",
    "    .write.mode(\"overwrite\")\n",
    "    .parquet(f\"{output_base}/monthly_trend_parquet\")\n",
    ")\n",
    "(\n",
    "    monthly_trend_df\n",
    "    .write.mode(\"overwrite\")\n",
    "    .json(f\"{output_base}/monthly_trend_json\")\n",
    ")\n",
    "\n",
    "(\n",
    "    top_category_df\n",
    "    .write.mode(\"overwrite\")\n",
    "    .parquet(f\"{output_base}/top_category_parquet\")\n",
    ")\n",
    "(\n",
    "    top_category_df\n",
    "    .write.mode(\"overwrite\")\n",
    "    .json(f\"{output_base}/top_category_json\")\n",
    ")\n",
    "\n",
    "print(\"Wrote results under:\", output_base)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
