{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Rishabh Johri\n",
        "\n",
        "rjohri@deloitte.com"
      ],
      "metadata": {
        "id": "Q-G3tEeAQqLr"
      },
      "id": "Q-G3tEeAQqLr"
    },
    {
      "cell_type": "markdown",
      "id": "b978228a",
      "metadata": {
        "id": "b978228a"
      },
      "source": [
        "# Part 3: Spark SQL & DataFrames\n",
        "This notebook implements Part 3 of the graded assessment:\n",
        "- Load CSVs (customers, orders, products)\n",
        "- Run Spark SQL queries (total spend > X, monthly trends, top-selling category)\n",
        "- Save results as Parquet and JSON\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6e1f266e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "6e1f266e",
        "outputId": "9a2c9de7-2589-45dd-905c-9476a5e5cab3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7d8e281f0470>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://de9233257390:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>RetailAnalytics-Part3</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip -q install pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"RetailAnalytics-Part3\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9347cd4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9347cd4a",
        "outputId": "2da0d51f-0703-4f70-bfa0-45ca5bb3635a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers columns: ['customer_id', 'name', 'country', 'age', 'gender']\n",
            "Orders columns: ['order_id', 'customer_id', 'product', 'category', 'quantity', 'price', 'order_date']\n",
            "Products columns: ['product', 'category', 'price']\n"
          ]
        }
      ],
      "source": [
        "customers_path = \"/content/customers.csv\"\n",
        "orders_path    = \"/content/orders.csv\"\n",
        "products_path  = \"/content/products.csv\"\n",
        "\n",
        "customers_df = spark.read.csv(customers_path, header=True, inferSchema=True)\n",
        "orders_df    = spark.read.csv(orders_path,    header=True, inferSchema=True)\n",
        "products_df  = spark.read.csv(products_path,  header=True, inferSchema=True)\n",
        "\n",
        "print(\"Customers columns:\", customers_df.columns)\n",
        "print(\"Orders columns:\", orders_df.columns)\n",
        "print(\"Products columns:\", products_df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5804badd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5804badd",
        "outputId": "17b67152-6b67-46ab-e837-b4113d2086a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+\n",
            "|order_date|revenue|\n",
            "+----------+-------+\n",
            "|2023-01-01|799.96 |\n",
            "|2023-01-02|29.97  |\n",
            "|2023-01-03|29.98  |\n",
            "|2023-01-04|19.98  |\n",
            "|2023-01-05|44.97  |\n",
            "+----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def first_present(df, candidates):\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "ord_qty_col = first_present(orders_df, [\"quantity\", \"qty\", \"Quantity\"])\n",
        "ord_unit_price_col = first_present(orders_df, [\"unit_price\", \"UnitPrice\", \"unitprice\", \"price_per_unit\"])\n",
        "ord_total_amt_col = first_present(orders_df, [\"total_amount\", \"TotalAmount\", \"amount\", \"Amount\", \"order_amount\"])\n",
        "ord_price_col = first_present(orders_df, [\"price\", \"Price\", \"unit_price\", \"UnitPrice\"])\n",
        "ord_date_col = first_present(orders_df, [\"order_date\", \"OrderDate\", \"date\", \"Date\", \"order_datetime\", \"timestamp\"])\n",
        "\n",
        "if ord_date_col is None:\n",
        "    raise ValueError(\"Could not find an order date column in orders file.\")\n",
        "\n",
        "orders_with_date = orders_df.withColumn(\n",
        "    \"_order_ts\",\n",
        "    F.to_timestamp(F.col(ord_date_col))\n",
        ").withColumn(\n",
        "    \"order_date\",\n",
        "    F.to_date(F.col(\"_order_ts\"))\n",
        ").drop(\"_order_ts\")\n",
        "\n",
        "if ord_qty_col and ord_unit_price_col:\n",
        "    orders_clean = orders_with_date.withColumn(\n",
        "        \"revenue\",\n",
        "        F.col(ord_qty_col).cast(\"double\") * F.col(ord_unit_price_col).cast(\"double\")\n",
        "    )\n",
        "elif ord_total_amt_col:\n",
        "    orders_clean = orders_with_date.withColumn(\n",
        "        \"revenue\",\n",
        "        F.col(ord_total_amt_col).cast(\"double\")\n",
        "    )\n",
        "elif ord_qty_col and ord_price_col:\n",
        "    orders_clean = orders_with_date.withColumn(\n",
        "        \"revenue\",\n",
        "        F.col(ord_qty_col).cast(\"double\") * F.col(ord_price_col).cast(\"double\")\n",
        "    )\n",
        "else:\n",
        "    raise ValueError(\"Could not derive revenue.\")\n",
        "\n",
        "orders_clean.select(\"order_date\",\"revenue\").show(5, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0ce18efa",
      "metadata": {
        "id": "0ce18efa"
      },
      "outputs": [],
      "source": [
        "customers_df.createOrReplaceTempView(\"customers\")\n",
        "orders_clean.createOrReplaceTempView(\"orders\")\n",
        "products_df.createOrReplaceTempView(\"products\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# figure out join keys\n",
        "cust_key = None\n",
        "for c in [\"customer_id\", \"cust_id\", \"CustomerID\", \"Customer_Id\"]:\n",
        "    if c in customers_df.columns:\n",
        "        cust_key = c\n",
        "        break\n",
        "\n",
        "ord_cust_key = None\n",
        "for c in [\"customer_id\", \"cust_id\", \"CustomerID\", \"Customer_Id\"]:\n",
        "    if c in orders_clean.columns:\n",
        "        ord_cust_key = c\n",
        "        break\n",
        "\n",
        "if not cust_key or not ord_cust_key:\n",
        "    raise ValueError(\"Couldn't find a common customer key. Expected columns like customer_id/cust_id in both customers and orders.\")\n",
        "\n",
        "# Make a view that standardizes the join key name\n",
        "customers_std = customers_df.withColumnRenamed(cust_key, \"customer_id_std\")\n",
        "orders_std = orders_clean.withColumnRenamed(ord_cust_key, \"customer_id_std\")\n",
        "customers_std.createOrReplaceTempView(\"customers_std\")\n",
        "orders_std.createOrReplaceTempView(\"orders_std\")\n",
        "\n",
        "# Build SELECT and GROUP BY with explicit customer columns (no \"c.*\")\n",
        "cust_cols = customers_std.columns  # e.g., [\"customer_id_std\",\"name\",\"country\",\"age\",\"gender\"]\n",
        "select_cols = \", \".join([f\"c.`{c}`\" for c in cust_cols])\n",
        "group_by_cols = \", \".join([f\"c.`{c}`\" for c in cust_cols])\n",
        "\n",
        "X = 500.0  # adjust your threshold\n",
        "\n",
        "sql_customers_over_X = f\"\"\"\n",
        "SELECT\n",
        "  {select_cols},\n",
        "  ROUND(SUM(o.revenue), 2) AS total_spend\n",
        "FROM customers_std c\n",
        "JOIN orders_std o\n",
        "  ON c.customer_id_std = o.customer_id_std\n",
        "GROUP BY {group_by_cols}\n",
        "HAVING SUM(o.revenue) > {X}\n",
        "ORDER BY total_spend DESC\n",
        "\"\"\"\n",
        "\n",
        "customers_over_X_df = spark.sql(sql_customers_over_X)\n",
        "customers_over_X_df.show(20, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGKHTRW6R0v4",
        "outputId": "2710c934-d41b-4831-ec40-6c9d73654d82"
      },
      "id": "nGKHTRW6R0v4",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------+-------+---+------+-----------+\n",
            "|customer_id_std|name      |country|age|gender|total_spend|\n",
            "+---------------+----------+-------+---+------+-----------+\n",
            "|7              |Customer_7|USA    |28 |Male  |1084.89    |\n",
            "|8              |Customer_8|Canada |23 |Male  |629.95     |\n",
            "+---------------+----------+-------+---+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "995c08e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "995c08e0",
        "outputId": "ce2992f6-9c47-486d-e592-7d294c7319df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------------+-----------+\n",
            "|year_month|monthly_revenue|order_count|\n",
            "+----------+---------------+-----------+\n",
            "|2023-01   |2554.7         |10         |\n",
            "+----------+---------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sql_monthly_trend = \"\"\"\n",
        "SELECT\n",
        "  DATE_FORMAT(order_date, 'yyyy-MM') AS year_month,\n",
        "  ROUND(SUM(revenue), 2) AS monthly_revenue,\n",
        "  COUNT(*) AS order_count\n",
        "FROM orders_std\n",
        "GROUP BY DATE_FORMAT(order_date, 'yyyy-MM')\n",
        "ORDER BY year_month\n",
        "\"\"\"\n",
        "\n",
        "monthly_trend_df = spark.sql(sql_monthly_trend)\n",
        "monthly_trend_df.show(50, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a18afecd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a18afecd",
        "outputId": "51a7d2e3-55dc-4cea-bf0a-3de7fd94fedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+----------+\n",
            "|category   |total_revenue|order_rows|\n",
            "+-----------+-------------+----------+\n",
            "|Sports     |1234.86      |4         |\n",
            "|Electronics|599.97       |1         |\n",
            "|Clothing   |419.96       |2         |\n",
            "|Books      |269.94       |2         |\n",
            "|Grocery    |29.97        |1         |\n",
            "+-----------+-------------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "customers_std.createOrReplaceTempView(\"customers_std\")\n",
        "orders_std.createOrReplaceTempView(\"orders_std\")\n",
        "products_df.createOrReplaceTempView(\"products\")\n",
        "\n",
        "# 1) Detect join key candidates present in each table\n",
        "candidate_keys = [\"product_id\", \"prod_id\", \"product\", \"sku\", \"ProductID\", \"Product_Id\", \"Product\"]\n",
        "\n",
        "join_key_orders = next((c for c in candidate_keys if c in orders_std.columns), None)\n",
        "join_key_products = next((c for c in candidate_keys if c in products_df.columns), None)\n",
        "\n",
        "if not join_key_orders or not join_key_products:\n",
        "    raise ValueError(\n",
        "        f\"Couldn't find a common product key. \"\n",
        "        f\"Orders has {orders_std.columns}; Products has {products_df.columns}. \"\n",
        "        f\"Expected one of {candidate_keys} in both.\"\n",
        "    )\n",
        "\n",
        "# 2) Detect category column in products\n",
        "cat_candidates = [\"category\", \"Category\", \"category_name\", \"CategoryName\"]\n",
        "cat_col = next((c for c in cat_candidates if c in products_df.columns), None)\n",
        "if not cat_col:\n",
        "    raise ValueError(f\"No category column found in products. Expected one of {cat_candidates}.\")\n",
        "\n",
        "# 3) Standardize column names for a clean join\n",
        "products_std = (\n",
        "    products_df\n",
        "    .withColumnRenamed(join_key_products, \"prod_key_std\")\n",
        "    .withColumnRenamed(cat_col, \"category_std\")\n",
        ")\n",
        "orders_w_prod = (\n",
        "    orders_std\n",
        "    .withColumnRenamed(join_key_orders, \"prod_key_std\")\n",
        ")\n",
        "\n",
        "products_std.createOrReplaceTempView(\"products_std\")\n",
        "orders_w_prod.createOrReplaceTempView(\"orders_w_prod\")\n",
        "\n",
        "# 4) Run SQL using the standardized join key\n",
        "sql_top_category = \"\"\"\n",
        "SELECT\n",
        "  p.category_std AS category,\n",
        "  ROUND(SUM(o.revenue), 2) AS total_revenue,\n",
        "  COUNT(*) AS order_rows\n",
        "FROM orders_w_prod o\n",
        "JOIN products_std p\n",
        "  ON o.prod_key_std = p.prod_key_std\n",
        "GROUP BY p.category_std\n",
        "ORDER BY total_revenue DESC\n",
        "\"\"\"\n",
        "\n",
        "top_category_df = spark.sql(sql_top_category)\n",
        "top_category_df.show(20, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "de0c145b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de0c145b",
        "outputId": "34a71d6c-085b-427a-eb1f-eb227b7931d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote results under: /content/output/retail_analytics\n"
          ]
        }
      ],
      "source": [
        "output_base = \"/content/output/retail_analytics\"\n",
        "\n",
        "(\n",
        "    customers_over_X_df\n",
        "    .coalesce(1)\n",
        "    .write.mode(\"overwrite\")\n",
        "    .parquet(f\"{output_base}/customers_over_X_parquet\")\n",
        ")\n",
        "(\n",
        "    customers_over_X_df\n",
        "    .coalesce(1)\n",
        "    .write.mode(\"overwrite\")\n",
        "    .json(f\"{output_base}/customers_over_X_json\")\n",
        ")\n",
        "\n",
        "(\n",
        "    monthly_trend_df\n",
        "    .write.mode(\"overwrite\")\n",
        "    .parquet(f\"{output_base}/monthly_trend_parquet\")\n",
        ")\n",
        "(\n",
        "    monthly_trend_df\n",
        "    .write.mode(\"overwrite\")\n",
        "    .json(f\"{output_base}/monthly_trend_json\")\n",
        ")\n",
        "\n",
        "(\n",
        "    top_category_df\n",
        "    .write.mode(\"overwrite\")\n",
        "    .parquet(f\"{output_base}/top_category_parquet\")\n",
        ")\n",
        "(\n",
        "    top_category_df\n",
        "    .write.mode(\"overwrite\")\n",
        "    .json(f\"{output_base}/top_category_json\")\n",
        ")\n",
        "\n",
        "print(\"Wrote results under:\", output_base)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iLW5YQtsTRNN"
      },
      "id": "iLW5YQtsTRNN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}